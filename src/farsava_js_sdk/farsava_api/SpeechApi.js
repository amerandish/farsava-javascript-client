/**
 * Farsava API
 * Farsava API. Speech Recognition and Text to Speech by applying powerful deep neural network models.
 *
 * OpenAPI spec version: 1.0.5
 * Contact: amir@amerandish.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 *
 */


import ApiClient from "../ApiClient";
import ASRRequestBodyData from '../farsava_model/ASRRequestBodyData';
import ASRRequestBodyURI from '../farsava_model/ASRRequestBodyURI';
import ASRResponseBody from '../farsava_model/ASRResponseBody';
import Error from '../farsava_model/Error';
import HealthCheckResponseBody from '../farsava_model/HealthCheckResponseBody';

/**
* Speech service.
* @module farsava_js_sdk/farsava_api/SpeechApi
* @version 1.0.5
*/
export default class SpeechApi {

    /**
    * Constructs a new SpeechApi. 
    * @alias module:farsava_js_sdk/farsava_api/SpeechApi
    * @class
    * @param {module:farsava_js_sdk/ApiClient} [apiClient] Optional API client implementation to use,
    * default to {@link module:farsava_js_sdk/ApiClient#instance} if unspecified.
    */
    constructor(apiClient) {
        this.apiClient = apiClient || ApiClient.instance;
    }


    /**
     * Callback function to receive the result of the deleteTranscription operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~deleteTranscriptionCallback
     * @param {String} error Error message, if any.
     * @param data This operation does not return a value.
     * @param {String} response The complete HTTP response.
     */

    /**
     * DELETE /speech/transcriptions/{transcriptionId}
     * Deletes a transcription for a previous file using transcriptionId. *** 
     * @param {String} transcriptionId Id of the transcribed audio. It is a UUID string provided in the speech recognition result. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~deleteTranscriptionCallback} callback The callback function, accepting three arguments: error, data, response
     */
    deleteTranscription(transcriptionId, callback) {
      let postBody = null;
      // verify the required parameter 'transcriptionId' is set
      if (transcriptionId === undefined || transcriptionId === null) {
        throw new Error("Missing the required parameter 'transcriptionId' when calling deleteTranscription");
      }

      let pathParams = {
        'transcriptionId': transcriptionId
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = [];
      let accepts = ['application/json'];
      let returnType = null;
      return this.apiClient.callApi(
        '/speech/transcriptions/{transcriptionId}', 'DELETE',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }

    /**
     * Callback function to receive the result of the getTranscription operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~getTranscriptionCallback
     * @param {String} error Error message, if any.
     * @param {module:farsava_js_sdk/farsava_model/ASRResponseBody} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * GET /speech/transcriptions/{transcriptionId}
     * Transcription endpoint enable us to retrieve a previous speech recognition result or inform us on a long running speech recognition status. To access a speech recognition result transcriptionId should be provided.    ***    
     * @param {String} transcriptionId Id of the transcribed audio. It is a UUID string provided in the speech recognition result. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~getTranscriptionCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link module:farsava_js_sdk/farsava_model/ASRResponseBody}
     */
    getTranscription(transcriptionId, callback) {
      let postBody = null;
      // verify the required parameter 'transcriptionId' is set
      if (transcriptionId === undefined || transcriptionId === null) {
        throw new Error("Missing the required parameter 'transcriptionId' when calling getTranscription");
      }

      let pathParams = {
        'transcriptionId': transcriptionId
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = [];
      let accepts = ['application/json'];
      let returnType = ASRResponseBody;
      return this.apiClient.callApi(
        '/speech/transcriptions/{transcriptionId}', 'GET',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }

    /**
     * Callback function to receive the result of the recognize operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~recognizeCallback
     * @param {String} error Error message, if any.
     * @param {module:farsava_js_sdk/farsava_model/ASRResponseBody} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * POST /speech/asr
     * ## Performs synchronous speech recognition  *** This resource receives audio data in different formats and transcribes the audio using state-of-the-art deep neural networks. It performs synchronous speech recognition and the result will be availble after all audio has been sent and processed. This endpoint is designed for transcription of short audio files upto 1 minute. *** Using *config* object you can can specify audio configs such as *audioEncoding* and *sampleRateHertz*. We will support different languages so you can choose the *languageCode*. Using *asrModel* and *languageModel* in config you can use customized models. Refer to *asrLongRunning* and *WebSocket API* for longer audio transcriptions. 
     * @param {module:farsava_js_sdk/farsava_model/ASRRequestBodyData} aSRRequestBodyData ## Audio *data* along with the customized *config* is posted to this service for speech recognition. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~recognizeCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link module:farsava_js_sdk/farsava_model/ASRResponseBody}
     */
    recognize(aSRRequestBodyData, callback) {
      let postBody = aSRRequestBodyData;
      // verify the required parameter 'aSRRequestBodyData' is set
      if (aSRRequestBodyData === undefined || aSRRequestBodyData === null) {
        throw new Error("Missing the required parameter 'aSRRequestBodyData' when calling recognize");
      }

      let pathParams = {
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = ['application/json'];
      let accepts = ['application/json'];
      let returnType = ASRResponseBody;
      return this.apiClient.callApi(
        '/speech/asr', 'POST',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }

    /**
     * Callback function to receive the result of the recognizeLive operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~recognizeLiveCallback
     * @param {String} error Error message, if any.
     * @param {module:farsava_js_sdk/farsava_model/ASRResponseBody} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * GET /speech/asrlive
     * ## Performs asynchronous live speech recognition using websocket *** This resource establish a websocket with client and receives audio data using websocket. It will start transcribing the audio using state-of-the-art deep neural networks and returns the partial results on the websocket. This endpoint is designed for transcription of stream audio data upto 15 minute. It will send back partial (status&#x3D;partial) result everytime it transcribes an endpoint. After client sends the close signal, it will receive a ASRResponseBody with status&#x3D;done. *** Using *config* object you can can specify audio configs such as *audioEncoding* and *sampleRateHertz*. We will support different languages so you can choose the *languageCode*. Using *asrModel* and *languageModel* in config you can use customized models. Refer to *ASRLongRuning API* for long audio speech recognition. Refer to *ASR API* for fast recognition for short audio files. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~recognizeLiveCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link module:farsava_js_sdk/farsava_model/ASRResponseBody}
     */
    recognizeLive(callback) {
      let postBody = null;

      let pathParams = {
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = [];
      let accepts = ['application/json'];
      let returnType = ASRResponseBody;
      return this.apiClient.callApi(
        '/speech/asrlive', 'GET',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }

    /**
     * Callback function to receive the result of the recognizeLongRunning operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~recognizeLongRunningCallback
     * @param {String} error Error message, if any.
     * @param {module:farsava_js_sdk/farsava_model/ASRResponseBody} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * POST /speech/asrlongrunning
     * ## Performs asynchronous speech recognition  *** This resource receives a uri containing the audio resource, download it and transcribes the audio using state-of-the-art deep neural networks. It performs asynchronous speech recognition and the result will be availble using transcription endpoint. This endpoint is designed for transcription of long audio files upto 240 minute. *** Using *config* object you can can specify audio configs such as *audioEncoding* and *sampleRateHertz*. We will support different languages so you can choose the *languageCode*. Using *asrModel* and *languageModel* in config you can use customized models. Refer to *WebSocket API* for speech recognition with streams. Refer to *ASR API* for fast recognition for short audio files. 
     * @param {module:farsava_js_sdk/farsava_model/ASRRequestBodyURI} aSRRequestBodyURI post uri and configs to this service for asr. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~recognizeLongRunningCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link module:farsava_js_sdk/farsava_model/ASRResponseBody}
     */
    recognizeLongRunning(aSRRequestBodyURI, callback) {
      let postBody = aSRRequestBodyURI;
      // verify the required parameter 'aSRRequestBodyURI' is set
      if (aSRRequestBodyURI === undefined || aSRRequestBodyURI === null) {
        throw new Error("Missing the required parameter 'aSRRequestBodyURI' when calling recognizeLongRunning");
      }

      let pathParams = {
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = ['application/json'];
      let accepts = ['application/json'];
      let returnType = ASRResponseBody;
      return this.apiClient.callApi(
        '/speech/asrlongrunning', 'POST',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }

    /**
     * Callback function to receive the result of the speechHealthCheck operation.
     * @callback module:farsava_js_sdk/farsava_api/SpeechApi~speechHealthCheckCallback
     * @param {String} error Error message, if any.
     * @param {module:farsava_js_sdk/farsava_model/HealthCheckResponseBody} data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * GET /speech/healthcheck
     * ## speech health check endpoint. *** This endpoint will return a simple json including **service status** and **API version**. 
     * @param {module:farsava_js_sdk/farsava_api/SpeechApi~speechHealthCheckCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link module:farsava_js_sdk/farsava_model/HealthCheckResponseBody}
     */
    speechHealthCheck(callback) {
      let postBody = null;

      let pathParams = {
      };
      let queryParams = {
      };
      let headerParams = {
      };
      let formParams = {
      };

      let authNames = ['bearerAuth'];
      let contentTypes = [];
      let accepts = ['application/json'];
      let returnType = HealthCheckResponseBody;
      return this.apiClient.callApi(
        '/speech/healthcheck', 'GET',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, null, callback
      );
    }


}
